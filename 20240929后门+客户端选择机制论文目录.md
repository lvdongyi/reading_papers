# Backdoor

| Title                                                        | Conference / Journal                                      |                                                              |
| ------------------------------------------------------------ | --------------------------------------------------------- | ------------------------------------------------------------ |
| [DBA: DISTRIBUTED BACKDOOR ATTACKS AGAINST FEDERATED LEARNING](https://openreview.net/pdf?id=rkgyS0VFvr) | ICLR 2020                                                 | 将全局触发模式分解为不同的局部模式，并分别嵌入到不同Adversary的训练集中 |
| [How To Backdoor Federated Learning](https://proceedings.mlr.press/v108/bagdasaryan20a/bagdasaryan20a.pdf) | ICML                                                      | 模型替换攻击                                                 |
| [Coordinated Backdoor Attacks against Federated Learning with Model-Dependent Triggers](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9713908) | IEEE Network 2022                                         | 基于攻击者的本地模型生成trigger进行后门攻击                  |
| [A Gradient Control Method for Backdoor Attacks on Parameter-Efficient Tuning](https://aclanthology.org/2023.acl-long.194.pdf)] | ACL 2023                                                  | 使用梯度控制方法巩固攻击效果                                 |
| [Backdoor attacks and defenses in feature-partitioned collaborative learning](https://arxiv.org/pdf/2007.03608) | ICML 2020                                                 | 即使没有访问标签的参与方也能成功注入后门攻击+几种防御技术    |
| [Neurotoxin: Durable Backdoors in Federated Learning](https://proceedings.mlr.press/v162/zhang22w/zhang22w.pdf) | ICML 2022                                                 | 一行代码插入后门攻击                                         |
| [Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling](https://arxiv.org/pdf/2204.14017) | ACL 2022                                                  | 通过NLP中的稀有word embedding进行模型投毒攻击                |
| [Attack of the Tails: Yes, You Really Can Backdoor Federated Learning](https://proceedings.neurips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf) | Nips 2020                                                 | 针对Edge-case进行标签翻转                                    |
| [A Little Is Enough: Circumventing Defenses For Distributed Learning](https://proceedings.neurips.cc/paper_files/paper/2019/file/ec1c59141046cd1866bbbcdfb6ae31d4-Paper.pdf) | ICML                                                      | 能够避开基于方差的防御机制的攻击方法                         |
| [Backdoor Learning: A Survey](https://arxiv.org/abs/2007.08745) | IEEE Transactions on Neural Networks and Learning Systems | 综述                                                         |

#  贡献度评估

| Title                                                        | Conference / Journal                                         |                                                              |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| [GTG-Shapley: Efficient and Accurate Participant Contribution Evaluation in Federated Learning](https://dl.acm.org/doi/pdf/10.1145/3501811) | ACM Transactions on intelligent Systems and Technology (TIST), 2022 | 从梯度更新中重构联邦学习模型来计算Shapley值                  |
| [Fair and efficient contribution valuation for vertical federated learning](https://arxiv.org/pdf/2201.02658) | ICLR 2024                                                    | 一种基于Shapley值的贡献评估指标                              |
| [Efficient Participant Contribution Evaluation for Horizontal and Vertical Federated Learning](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9835159) | ICLR 2024                                                    | 高效估计Shapley+根据参与者每个epoch的贡献动态调整权重        |
| [Data Shapley: Equitable Valuation of Data for Machine Learning](https://proceedings.mlr.press/v97/ghorbani19c/ghorbani19c.pdf) | ICML                                                         | 针对数据的Shapley                                            |
| [Towards Fair and Privacy-Preserving Federated Deep Models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9098045) | IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS        | 本地可信度相互评估机制，每次全局更新后，每个Client获得的新模型都不同 |
| [FedSim: Similarity guided model aggregation for Federated Learning](https://www.sciencedirect.com/science/article/pii/S0925231221016039) | [Neurocomputing](https://www.sciencedirect.com/journal/neurocomputing) | 利用Client之间的相似度计算贡献                               |
| [Incentive Mechanism for Horizontal Federated Learning Based on Reputation and Reverse Auction](https://dl.acm.org/doi/pdf/10.1145/3442381.3449888) | Proceedings of the Web Conference 2021                       | 基于声誉的联邦学习激励机制                                   |
| [Understanding Black-box Predictions via Influence Functions](https://proceedings.mlr.press/v70/koh17a/koh17a.pdf) | ICML                                                         | 使用影响函数识别出对给定预测最有影响力的Training Point       |
| [Towards Understanding the Influence of Individual Clients in Federated Learning](https://ojs.aaai.org/index.php/AAAI/article/view/17263/17070) | AAAI-21                                                      | Fed-Influence量化个别客户端对模型的影响                      |

加上聚合的贡献度评估

行是问题 列是方法 做个excel表

