#  大小模型

| Title                                                        | Conference / Journal                | filename                                         |                                                              |
| ------------------------------------------------------------ | ----------------------------------- | ------------------------------------------------ | ------------------------------------------------------------ |
| Synergetic Event Understanding: A Collaborative Approach to Cross-Document Event Coreference Resolution with Large Language Models | ACL 2024                            | [2406.02148v1.pdf](2406.02148v1.pdf)             | 大小模型协同的跨文档理解                                     |
| Prover-Verifier Games improve legibility of LLM outputs      | 量子位（OpenAI发的）                | [2407.13692v2.pdf](2407.13692v2.pdf)             | 大小模型相互博弈                                             |
| On Giant’s Shoulders: Effortless Weak to Strong by Dynamic Logits Fusion | Nips 2024                           | [2406.15480v1.pdf](2406.15480v1.pdf)             | 微调小模型，将他们的知识迁移到更大的模型                     |
| Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision | OpenAI发的                          | [2312.09390v1.pdf](2312.09390v1.pdf)             | 用弱模型监督强模型                                           |
| Contrastive Decoding: Open-ended Text Generation as Optimization | ACL 2023（CS224N的TA发的）          | [2210.15097v2.pdf](2210.15097v2.pdf)             | 一种Decoding方式，灵感来自大模型的缺陷在小模型中更加明显，无需重训练 |
| Parameter-efficient Tuning for Large Language Model without Calculating Its Gradients | EMNLP 2023                          | [2023.emnlp-main.22.pdf](2023.emnlp-main.22.pdf) | 使用桥接模型，将小模型学习到的任务特定模块迁移到大模型中     |
| Aligner: Efficient Alignment by Learning to Correct          | Cited by 31<br />Rejected By ICLR   | [2402.02416v4.pdf](2402.02416v4.pdf)             | 小模型学习模型给出的优选答案和非优选答案之间的校正残差，得到矫正后的数据，用于训练上游模型 |
| An Emulator for Fine-Tuning Large Language Models using Small Language Models | ICLR 2024                           | [2310.12962v1.pdf](2310.12962v1.pdf)             | 小模型修正大模型输出，Speculative Decoding                   |
| Tuning Language Models by Proxy                              | COLM 2024                           | [2401.08565v4.pdf](2401.08565v4.pdf)             | 微调小模型，将小模型微调前后的差值应用到大模型的预测上       |
| Small Models are Valuable Plug-ins for Large Language Models | ACL 2024                            | [2305.08848v1.pdf](2305.08848v1.pdf)             | 微调小模型；将小模型的输出送入大模型                         |
| DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter | Hugging Face发的                    | [1910.01108v4.pdf](1910.01108v4.pdf)             | 预训练阶段的知识蒸馏                                         |
| PAYING MORE ATTENTION TO ATTENTION: IMPROVING THE PERFORMANCE OF CONVOLUTIONAL NEURAL NETWORKS VIA ATTENTION TRANSFER | ICLR 2017                           | [1612.03928v3.pdf](1612.03928v3.pdf)             | 学生网络共享教师网络的权重                                   |
| Want To Reduce Labeling Cost? GPT-3 Can Help                 | Microsoft发的                       | [2108.13487v1.pdf](2108.13487v1.pdf)             | 大模型对数据进行标签，用于小模型训练                         |
| Explanations from Large Language Models Make Small Reasoners Better | AAAI 2024 Workshop Oral             | [2210.06726v1.pdf](2210.06726v1.pdf)             | 用大模型生成的解释来改善小模型的训练                         |
| LESS: Selecting Influential Data for Targeted Instruction Tuning | ICML 2024                           |                                                  | 用小模型选择出高质量数据，微调大模型                         |
| [A Survey on Knowledge Distillation of Large Language Models](https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/tree/main) | 机器之心（陶大程团队联合港大、UMD） | [2402.13116v3.pdf](2402.13116v3.pdf)             | 大模型知识蒸馏综述                                           |
| What is the Role of Small Models in the LLM Era: A Survey    |                                     | [2409.06857v2.pdf](2409.06857v2.pdf)             | 大模型时代小模型的用途综述                                   |

